import streamlit as st
import requests
import pandas as pd
from datetime import datetime, timedelta
import calendar
from ftplib import FTP
import io
import pytz
import logging
from bs4 import BeautifulSoup # HTMLè§£æžã®ãŸã‚bs4ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š (ãƒ‡ãƒãƒƒã‚°ç”¨)
logging.basicConfig(level=logging.INFO)

# --- å®šæ•°è¨­å®š ---
# ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒ¼ã‚¸è«‹æ±‚æ›¸ãƒšãƒ¼ã‚¸ã®URL
SR_BASE_URL = "https://www.showroom-live.com/organizer/show_rank_time_charge_hist_invoice_format" 
# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆãƒ•ã‚¡ã‚¤ãƒ«å
TARGET_FILENAME = "show_rank_time_charge_hist_invoice_format.csv"
# æ—¥æœ¬ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = pytz.timezone('Asia/Tokyo')

# --- è¨­å®šãƒ­ãƒ¼ãƒ‰ã¨èªè¨¼ ---
try:
    # ã‚ªãƒ¼ã‚¬ãƒŠã‚¤ã‚¶ãƒ¼Cookieã‚’å–å¾—
    AUTH_COOKIE_STRING = st.secrets["showroom"]["auth_cookie_string"]
    # FTPè¨­å®š
    FTP_CONFIG = {
        "host": st.secrets["ftp"]["host"],
        "user": st.secrets["ftp"]["user"],
        "password": st.secrets["ftp"]["password"],
        # FTPã‚µãƒ¼ãƒãƒ¼ä¸Šã®ç‰©ç†ãƒ‘ã‚¹ã‚’è¨­å®šã€‚
        # æˆåŠŸå®Ÿç¸¾ã®ã‚ã‚‹ãƒ‘ã‚¹æ§‹é€ ã«åˆã‚ã›ã¦ã€ãƒ›ã‚¹ãƒˆåã‚’ãƒ‘ã‚¹ã®èµ·ç‚¹ã«å«ã‚ã¾ã™ã€‚
        "target_path": "/mksoul-pro.com/showroom/sales-app_v2/db/show_rank_time_charge_hist_invoice_format.csv" 
    }
except KeyError as e:
    # secretsãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ã‚’æŒ¿å…¥ã—ã¦ã‚¨ãƒ©ãƒ¼ã‚’è¡¨ç¤º
    AUTH_COOKIE_STRING = "DUMMY"
    FTP_CONFIG = None
    st.error(f"ðŸš¨ èªè¨¼ã¾ãŸã¯FTPè¨­å®šãŒã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.streamlit/secrets.toml`ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ä¸è¶³: {e}")
    st.stop()


# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---

def get_target_months(years=2):
    """éŽåŽ»æŒ‡å®šå¹´æ•°åˆ†ã®å¹´æœˆ (YYYYMM) ã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    today = datetime.now(JST).date()
    target_months = []
    
    # 24ãƒ¶æœˆä»¥ä¸Šé¡ã‚‰ãªã„ã‚ˆã†ã«ä¸Šé™ã‚’è¨­å®š
    max_months_to_check = years * 12 + 1 

    for i in range(max_months_to_check):
        # ç¾åœ¨ã®æœˆã‹ã‚‰ i ãƒ¶æœˆå‰ã®æ—¥ä»˜ã‚’è¨ˆç®—
        month_ago = today - timedelta(days=30 * i)
        
        # å–å¾—å¯¾è±¡ã®å¹´æœˆã‚’ YYYYMM å½¢å¼ã§æ ¼ç´
        target_months.append(month_ago.strftime("%Y%m"))
        
        # å–å¾—ã™ã‚‹å¹´æœˆã®ãƒªã‚¹ãƒˆã¯é‡è¤‡ã‚’æŽ’é™¤
        target_months = sorted(list(set(target_months)), reverse=True)
        
        # å–å¾—å¯¾è±¡ãŒæŒ‡å®šã•ã‚ŒãŸå¹´æ•°ã«é”ã—ãŸã‚‰çµ‚äº†
        if len(target_months) >= years * 12:
             break

    # å¸¸ã«æœ€æ–°ã®12ã‹æœˆ*2å¹´(24ãƒ¶æœˆ)åˆ†ã‚’è¿”ã™
    return target_months[:years*12]


@st.cache_data(ttl=600)
def fetch_month_data(month_str, auth_cookie_string):
    """ç‰¹å®šã®æœˆ (YYYYMM) ã®ãƒ‡ãƒ¼ã‚¿ã‚’SHOWROOMã®ãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—ãƒ»è§£æžã™ã‚‹"""
    # URLã«å¹´æœˆ (YYYYMM) ã‚’å«ã‚ã‚‹
    url = f"{SR_BASE_URL}?month={month_str}"
    
    headers = {
        "Cookie": auth_cookie_string,
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # 200ä»¥å¤–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã¯ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹
    except requests.exceptions.HTTPError as e:
        # 404 Not Found ãªã©ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†
        logging.error(f"HTTP Error for {month_str}: {e}")
        return None
    except requests.exceptions.RequestException as e:
        # ãã®ä»–ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼
        logging.error(f"Request Error for {month_str}: {e}")
        return None

    # HTMLè§£æž
    soup = BeautifulSoup(response.content, 'html.parser')

    # ãƒ†ãƒ¼ãƒ–ãƒ«è¦ç´ ã‚’æ¤œç´¢ (ã“ã“ã§ã¯IDã‚„ã‚¯ãƒ©ã‚¹ã§ã¯ãªãã€æ§‹é€ ã§æŽ¢ã™)
    # å…·ä½“çš„ãªãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ãŒä¸æ˜ŽãªãŸã‚ã€ã“ã“ã§ã¯ä¸€æ—¦ãƒšãƒ¼ã‚¸å†…ã®å…¨ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŽ¢ã™
    tables = soup.find_all('table')
    
    if not tables:
        # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã‚„ã€ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ãªã„å ´åˆï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„ï¼‰
        # ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª (ä»Šå›žã¯Cookieèªè¨¼ãªã®ã§ä¸è¦ãªå¯èƒ½æ€§ã‚ã‚Š)
        logging.warning(f"No tables found for month {month_str}. Check login status or page structure.")
        return None

    # é©åˆ‡ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç‰¹å®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚ä»Šå›žã¯æœ€åˆã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è©¦ã™
    try:
        # Pandasã§HTMLã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç›´æŽ¥èª­ã¿è¾¼ã‚€
        df_list = pd.read_html(response.text, header=0, encoding='utf-8')
        # è¤‡æ•°ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã€æœ€ã‚‚ãƒ‡ãƒ¼ã‚¿ãŒå¤šã„ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸ã¶ãªã©èª¿æ•´ãŒå¿…è¦ã ãŒã€
        # ã“ã“ã§ã¯ä¸€æ—¦ã€æœ€ã‚‚é©åˆ‡ãªãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆæœ€åˆã®ãƒ†ãƒ¼ãƒ–ãƒ«ãªã©ï¼‰ã‚’è©¦ã™
        
        # ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒ¼ã‚¸ã®è«‹æ±‚æ›¸ãƒ•ã‚©ãƒ¼ãƒžãƒƒãƒˆã¯ä¸€ã¤ã®ä¸»è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æŒã¤ã¨ä»®å®šã—ã€
        # ã‚«ãƒ©ãƒ åã§ãƒ˜ãƒƒãƒ€ãƒ¼ãŒé©åˆ‡ã«æ¤œå‡ºã•ã‚ŒãŸã‚‚ã®ã‚’æŽ¢ã™
        
        target_df = None
        for df in df_list:
            # å¿…è¦ãªã‚«ãƒ©ãƒ åã®ä¸€éƒ¨ ('ãƒ«ãƒ¼ãƒ å', 'æ™‚é–“å¸¯', 'æ™‚é–“(h)') ãªã©ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if any(col in df.columns for col in ['ãƒ«ãƒ¼ãƒ å', 'æ™‚é–“å¸¯', 'æ™‚é–“(h)']) or len(df.columns) > 5:
                target_df = df
                break
        
        if target_df is None:
            logging.warning(f"Could not find the target table in {month_str}.")
            return None

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        return clean_data(target_df, month_str)

    except ValueError as e:
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã€ã¾ãŸã¯è§£æžã§ããªã„å ´åˆ
        logging.warning(f"Failed to parse HTML tables for {month_str}: {e}")
        return None


def clean_data(df, month_str):
    """å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ•´å½¢ãƒ»ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹"""
    
    # 1. ä¸è¦ãªãƒ•ãƒƒã‚¿ãƒ¼è¡Œã®å‰Šé™¤ (ä¾‹: 'åˆè¨ˆ'ã‚’å«ã‚€è¡Œ)
    # NaNãŒå¤šã„è¡Œã‚„ã€ç‰¹å®šã®é›†è¨ˆè¡Œã‚’å‰Šé™¤ã™ã‚‹å‡¦ç†ã‚’ã“ã“ã«è¿½åŠ 
    # ã‚«ãƒ©ãƒ ãŒæ¨™æº–åŒ–ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ä»Šå›žã¯ã‚«ãƒ©ãƒ æ•°ãŒå¤šã„è¡Œã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
    # 1è¡Œç›®ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ãŸå¾Œã®è¡Œã‚’å¯¾è±¡ã¨ã™ã‚‹
    if 'åˆè¨ˆ' in df.to_string():
        df = df[~df.apply(lambda row: row.astype(str).str.contains('åˆè¨ˆ').any(), axis=1)]
    
    # NaNãŒå¤šã„ï¼ˆç©ºã®è¡Œï¼‰ã‚’å‰Šé™¤
    df.dropna(how='all', inplace=True)

    # 2. ã‚«ãƒ©ãƒ åã®æ¨™æº–åŒ– (SHOWROOMã®ãƒšãƒ¼ã‚¸æ§‹é€ ã«ä¾å­˜)
    # ãƒšãƒ¼ã‚¸ã‚’è§£æžã—ã¦ã€ã‚«ãƒ©ãƒ åã‚’ç‰¹å®šã—ã€æ¨™æº–åŒ–ã™ã‚‹
    
    # ãƒšãƒ¼ã‚¸ã«ã‚ˆã£ã¦ã‚«ãƒ©ãƒ åãŒå¤‰å‹•ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ç¢ºå®Ÿãªè­˜åˆ¥å­ã‚’è¦‹ã¤ã‘ã‚‹
    
    # æš«å®šçš„ãªã‚«ãƒ©ãƒ ãƒžãƒƒãƒ”ãƒ³ã‚°ï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦èª¿æ•´ãŒå¿…è¦ï¼‰
    column_mapping = {
        'ãƒ«ãƒ¼ãƒ å': 'room_name',
        'æ™‚é–“å¸¯': 'time_slot',
        'æ™‚é–“(h)': 'hours',
        'æ—¥': 'day_of_month',
        'ç¨®åˆ¥': 'type' # ä¾‹: 'é€šå¸¸' 'ãƒœãƒ¼ãƒŠã‚¹'
    }
    
    # æ—¢ã«æ¨™æº–åŒ–ã•ã‚ŒãŸåå‰ãŒã‚ã‚Œã°ãã®ã¾ã¾ã€ãã†ã§ãªã‘ã‚Œã°ãƒžãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨
    df.columns = [column_mapping.get(col, col) for col in df.columns]

    # 3. 'day_of_month' ã‚«ãƒ©ãƒ ã‹ã‚‰æ—¥ä»˜ã‚’ç”Ÿæˆã—ã€'date' ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
    if 'day_of_month' in df.columns:
        year = month_str[:4]
        month = month_str[4:]
        
        # æ—¥ä»˜ãŒæœ‰åŠ¹ãªæ•°å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ç„¡åŠ¹ãªè¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
        df['day_of_month'] = pd.to_numeric(df['day_of_month'], errors='coerce')
        df.dropna(subset=['day_of_month'], inplace=True)
        df['day_of_month'] = df['day_of_month'].astype(int)
        
        # 1ã€œæœˆæœ«æ—¥ã¾ã§ã®ç¯„å›²å†…ã®æ—¥ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        _, last_day = calendar.monthrange(int(year), int(month))
        df = df[(df['day_of_month'] >= 1) & (df['day_of_month'] <= last_day)].copy()
        
        df['date_str'] = df.apply(
            lambda row: f"{year}/{month}/{row['day_of_month']:02d}", 
            axis=1
        )
        # JSTã®datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        df['date'] = pd.to_datetime(df['date_str'], format='%Y/%m/%d').dt.tz_localize(JST)
        df.drop(columns=['date_str', 'day_of_month'], inplace=True, errors='ignore')
    
    # 4. 'hours'ã‚’æ•°å€¤ã«å¤‰æ› (ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°NaNã€ãã®å¾Œå‰Šé™¤)
    if 'hours' in df.columns:
        df['hours'] = pd.to_numeric(df['hours'], errors='coerce')
        df.dropna(subset=['hours'], inplace=True)

    # 5. ä¸è¦ãªã‚«ãƒ©ãƒ ã‚’å‰Šé™¤ï¼ˆå…ƒã®ã‚«ãƒ©ãƒ åå…¨ã¦ãŒä¸æ˜ŽãªãŸã‚ã€æš«å®šçš„ã«å¿…é ˆé …ç›®ä»¥å¤–ã¯å‰Šé™¤ï¼‰
    final_columns = ['date', 'room_name', 'time_slot', 'hours', 'type']
    df = df[[col for col in final_columns if col in df.columns]].copy()
    
    # 6. 'month'ã‚«ãƒ©ãƒ ã‚’è¿½åŠ  (é›†è¨ˆç”¨ã«)
    df['month'] = month_str

    logging.info(f"Cleaned data for {month_str}: {len(df)} rows")
    return df


def ftp_upload(target_path, data_bytes):
    """æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’FTPã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹"""
    try:
        logging.info(f"Connecting to FTP host: {FTP_CONFIG['host']}")
        with FTP(FTP_CONFIG["host"]) as ftp:
            ftp.login(user=FTP_CONFIG["user"], passwd=FTP_CONFIG["password"])
            ftp.encoding = 'utf-8'

            # StringIOã§ã¯ãªãBytesIOã‚’ä½¿ç”¨ (ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ 'wb' ã®ãŸã‚)
            bio = io.BytesIO(data_bytes)
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ (STOr file)
            ftp.storbinary(f'STOR {target_path}', bio)
            logging.info(f"Successfully uploaded to: {target_path}")
            return True

    except Exception as e:
        st.error(f"FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è¨­å®šï¼ˆãƒ›ã‚¹ãƒˆåã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã€ãƒ‘ã‚¹ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {e}")
        logging.error(f"FTP Upload Error: {e}")
        return False


def run_data_update():
    """ãƒ‡ãƒ¼ã‚¿å–å¾—ã€æ•´å½¢ã€çµåˆã€FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®ä¸€é€£ã®å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹"""
    
    if not FTP_CONFIG:
        st.error("FTPè¨­å®šãŒæ­£ã—ããƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return

    # 1. å–å¾—å¯¾è±¡ã®å¹´æœˆãƒªã‚¹ãƒˆã‚’ç”Ÿæˆ
    target_months = get_target_months(years=2) # éŽåŽ»2å¹´åˆ†
    
    st.info(f"â³ éŽåŽ» {len(target_months)} ãƒ¶æœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™: {target_months[0]}ã€œ{target_months[-1]}é ƒ")
    
    all_data = []
    status_bar = st.progress(0)
    
    # 2. å„æœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»æ•´å½¢
    for i, month in enumerate(target_months):
        st.caption(f"Fetching data for {month}...")
        df = fetch_month_data(month, AUTH_COOKIE_STRING)
        if df is not None and not df.empty:
            all_data.append(df)
        
        status_bar.progress((i + 1) / len(target_months))

    status_bar.empty()
    
    if not all_data:
        st.error("ðŸ˜¢ å–å¾—å¯¾è±¡æœŸé–“ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚CookieãŒæœ‰åŠ¹ã‹ã€æœŸé–“å†…ã«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return
        
    # 3. å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
    final_df = pd.concat(all_data, ignore_index=True)
    
    # 4. é‡è¤‡è¡Œã®å‰Šé™¤ (room_name, date, time_slot, typeãŒä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’æœ€æ–°ã®ã‚‚ã®ã®ã¿æ®‹ã™)
    # é‡è¤‡åˆ¤å®šã®ã‚«ãƒ©ãƒ 
    # dateãŒæœ€ã‚‚é‡è¦ãªã®ã§ã€ date + room_name + time_slot + type ãŒé‡è¤‡åŸºæº–
    subset_cols = ['date', 'room_name', 'time_slot', 'type']
    final_df.sort_values(by='date', ascending=False, inplace=True) # æœ€æ–°ã®æ—¥ä»˜ã‚’å„ªå…ˆ
    
    before_drop_count = len(final_df)
    final_df.drop_duplicates(subset=subset_cols, keep='first', inplace=True)
    after_drop_count = len(final_df)
    
    st.success(f"ãƒ‡ãƒ¼ã‚¿æ•´å½¢å®Œäº†ï¼åˆè¨ˆ {after_drop_count} ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’çµ±åˆã—ã¾ã—ãŸã€‚")
    if before_drop_count != after_drop_count:
        st.caption(f"({before_drop_count - after_drop_count} ä»¶ã®å¤ã„é‡è¤‡ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ã¾ã—ãŸã€‚)")

    # 5. CSVãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
    # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã‚’é™¤åŽ»ã—ã¦ã€YYYY-MM-DD HH:MM:SSå½¢å¼ã®æ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜
    final_df['date'] = final_df['date'].dt.tz_convert(None).dt.strftime('%Y-%m-%d %H:%M:%S')

    csv_data = final_df.to_csv(index=False, encoding="utf-8-sig")
    csv_bytes = csv_data.encode("utf-8-sig")

    st.info(f"â˜ï¸ FTPã‚µãƒ¼ãƒãƒ¼ã¸ãƒ‡ãƒ¼ã‚¿ ({TARGET_FILENAME}) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
    
    # 6. FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    if ftp_upload(FTP_CONFIG["target_path"], csv_bytes):
        st.success("ðŸŽ‰ FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        
        # 7. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’æä¾›
        st.download_button(
            label="ðŸ“¥ çµ±åˆã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_bytes,
            file_name=f"showroom_time_charge_hist_{datetime.now(JST).strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
    else:
        st.error("FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è¨­å®šã¨ã‚µãƒ¼ãƒãƒ¼ã®ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")


# --- Streamlit UI ---

st.set_page_config(page_title="SHOWROOMã‚¿ã‚¤ãƒ ãƒãƒ£ãƒ¼ã‚¸å±¥æ­´çµ±åˆãƒ„ãƒ¼ãƒ«", layout="centered")

st.title("ðŸ’° SHOWROOM ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒ¼ã‚¸å±¥æ­´çµ±åˆãƒ„ãƒ¼ãƒ«")
st.markdown("---")

st.markdown("""
ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€SHOWROOMã‚ªãƒ¼ã‚¬ãƒŠã‚¤ã‚¶ãƒ¼ãƒšãƒ¼ã‚¸ã‹ã‚‰éŽåŽ»2å¹´åˆ†ã®ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒ¼ã‚¸å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ãƒ»çµ±åˆã—ã€
æŒ‡å®šã•ã‚ŒãŸFTPã‚µãƒ¼ãƒãƒ¼ä¸Šã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•ã§æ›´æ–°ã—ã¾ã™ã€‚
""")

if st.button("ðŸš€ ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼†FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ"):
    run_data_update()

st.markdown("---")
st.caption("â€» å®Ÿè¡Œã«ã¯ã€æœ‰åŠ¹ãªSHOWROOMã‚ªãƒ¼ã‚¬ãƒŠã‚¤ã‚¶ãƒ¼ã®Cookieã¨FTPæŽ¥ç¶šæƒ…å ±ãŒ`.streamlit/secrets.toml`ã«è¨­å®šã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
st.caption(f"ç¾åœ¨ã®FTPã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‘ã‚¹: `{FTP_CONFIG['target_path']}`")
