import streamlit as st
import requests
import pandas as pd
from datetime import datetime
import calendar
from ftplib import FTP
import io
import pytz
import logging

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š (Streamlit Cloudã§ã®ãƒ‡ãƒãƒƒã‚°ç”¨)
logging.basicConfig(level=logging.INFO)

# --- å®šæ•°è¨­å®š ---
# å–å¾—å…ƒã®åŸºæœ¬URL
SR_BASE_URL = "https://www.showroom-live.com/organizer/show_rank_time_charge_hist_invoice_format" # å¤‰æ•°åã‚’ä¿®æ­£
# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆãƒ•ã‚¡ã‚¤ãƒ«å
TARGET_FILENAME = "show_rank_time_charge_hist_invoice_format.csv"
# æ—¥æœ¬ã®ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³
JST = pytz.timezone('Asia/Tokyo')

# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•° ---

def get_target_months(years=2):
    """éå»Nå¹´é–“ã®æœˆãƒªã‚¹ãƒˆã‚’ 'YYYYå¹´MMæœˆåˆ†' å½¢å¼ã§ç”Ÿæˆã™ã‚‹"""
    today = datetime.now(JST)
    months = []
    
    # é¸æŠè‚¢ã®è¡¨ç¤ºã‚’å½“æœˆå«ã‚€éå»2å¹´åˆ†ç¨‹åº¦ã«é™å®š
    for y in range(today.year - years + 1, today.year + 1):
        for m in range(1, 13):
            if y == today.year and m > today.month:
                continue # ä»Šå¾Œã®æœˆã¯é™¤å¤–
            
            # YYYYå¹´MMæœˆåˆ† (ä¾‹: 2025å¹´10æœˆåˆ†)
            month_str = f"{y}å¹´{m:02d}æœˆåˆ†"
            
            # ãƒ‡ãƒ¼ã‚¿å–å¾—ã®fromãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«å¿…è¦ãªã€å¯¾è±¡æœˆã®1æ—¥00:00:00 JSTã®UNIXã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¨ˆç®—
            try:
                # å¯¾è±¡æœˆã®1æ—¥ 00:00:00 JST
                dt_obj_jst = datetime(y, m, 1, 0, 0, 0, tzinfo=JST)
                
                # JSTã®datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’UTCã«å¤‰æ›ã—ã¦ã‹ã‚‰timestampã‚’å–å¾—ã™ã‚‹ã“ã¨ã§ã€
                # æ­£ç¢ºã«JSTã®00:00:00ã‚’æŒ‡ã™UNIXã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å¾—ã‚‹
                timestamp = int(dt_obj_jst.astimezone(pytz.utc).timestamp())
                
                # æ¤œè¨¼ç”¨ï¼š
                # 2025å¹´10æœˆ1æ—¥ 00:00:00 JST -> 1759244400
                # 2025å¹´9æœˆ1æ—¥ 00:00:00 JST -> 1756652400
                
                months.append((month_str, timestamp))
            except ValueError:
                # å­˜åœ¨ã—ãªã„æœˆï¼ˆä¾‹: 2æœˆ30æ—¥ãªã©ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
                continue
                
    # æœ€æ–°ã®æœˆãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã«é€†é †ã«ã™ã‚‹
    return months[::-1]

def fetch_and_process_data(timestamp, cookie_string):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«åŸºã¥ã„ã¦SHOWROOMã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€æ•´å½¢ã™ã‚‹
    """
    st.info(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­... ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {timestamp}")
    
    try:
        # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—
        # SR_BASE_URLã‚’ä½¿ç”¨ (ä¿®æ­£æ¸ˆã¿)
        url = f"{SR_BASE_URL}?from={timestamp}" 
        headers = {
            # èªè¨¼ã«å¿…è¦ãªCookieã‚’è¨­å®š
            "Cookie": cookie_string,
            # ãƒ–ãƒ©ã‚¦ã‚¶ã¨ã—ã¦æŒ¯ã‚‹èˆã†ãŸã‚ã®User-Agentã‚’è¨­å®š
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36",
        }
        
        session = requests.Session()
        response = session.get(url, headers=headers, timeout=30)
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã«ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹
        
        # 2. HTMLã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿æŠ½å‡º (pandas.read_htmlã‚’ä½¿ç”¨)
        # HTMLå†…ã«ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã¨ä»®å®š
        tables = pd.read_html(response.text)
        
        if not tables:
            st.error("HTMLã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆå£²ä¸Šæƒ…å ±ï¼‰ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚CookieãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ã€ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãŒãƒšãƒ¼ã‚¸ä¸Šã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None
        
        # æœ€åˆã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ«ãƒ¼ãƒ ID, ãƒ«ãƒ¼ãƒ URL, ãƒ«ãƒ¼ãƒ å, åˆ†é…é¡, ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã‚’å«ã‚€ï¼‰ã¨ä»®å®š
        raw_df = tables[0]
        st.success(f"ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚è¡Œæ•°: {len(raw_df)}")
        
        # å–å¾—ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¡¨ç¤ºã—ã¦ç¢ºèª
        st.markdown("##### å–å¾—ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼ã¨æœ€åˆã®5è¡Œï¼‰")
        st.dataframe(raw_df.head())
        
        # 3. ãƒ‡ãƒ¼ã‚¿æ•´å½¢
        
        # --- ãƒ‡ãƒ¼ã‚¿æ•´å½¢ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆè¦ä»¶ã®ç‰¹æ®ŠCSVãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«åˆã‚ã›ã‚‹ï¼‰ ---
        
        # æä¾›ã•ã‚ŒãŸHTMLã‚¹ãƒ‹ãƒšãƒƒãƒˆã«åŸºã¥ãã€å¿…è¦ãªåˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š
        # 0: ãƒ«ãƒ¼ãƒ ID, 1: ãƒ«ãƒ¼ãƒ URL, 2: ãƒ«ãƒ¼ãƒ å, 3: åˆ†é…é¡, 4: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID
        # CSVã®1åˆ—ç›®: åˆ†é…é¡ (ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 3)
        # CSVã®2åˆ—ç›®: ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID (ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 4)
        
        AMOUNT_COL = 3
        ACCOUNT_ID_COL = 4 
        
        if ACCOUNT_ID_COL >= len(raw_df.columns) or AMOUNT_COL >= len(raw_df.columns):
            st.warning("DataFrameã®åˆ—æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆåˆ†é…é¡: 3, ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID: 4ï¼‰ãŒãƒ‡ãƒ¼ã‚¿ã¨ä¸€è‡´ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            return None
        
        # åˆ†é…é¡ã¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã®åˆ—ã‚’æŠ½å‡º
        # CSVå‡ºåŠ›ã®é †ç•ªã«åˆã‚ã›ã¦ [åˆ†é…é¡ã®åˆ—, ã‚¢ã‚«ã‚¦ãƒ³ãƒˆIDã®åˆ—] ã®é †ã§æŠ½å‡º
        df_extracted = raw_df.iloc[:, [AMOUNT_COL, ACCOUNT_ID_COL]].copy()
        
        # DataFrameã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ (æ•´å½¢ã®ãŸã‚ã«ä¸€æ™‚çš„ã«è¨­å®š)
        df_extracted.columns = ['åˆ†é…é¡', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID']
        
        # NaNã‚„åˆè¨ˆè¡Œãªã©ã‚’å‰Šé™¤ (åˆ†é…é¡ãŒæ•°å€¤ã§ãªã„è¡Œã‚’å‰Šé™¤ã™ã‚‹ãªã©)
        # æŠ½å‡ºã—ãŸåˆ†é…é¡ã®åˆ—ã‚’æ–‡å­—åˆ—ã«å¤‰æ›ã—ã€æ•°å€¤ã®ã¿ã‚’å«ã‚€è¡Œã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        # ã¾ãŸã€åˆ†é…é¡ã‹ã‚‰ã‚«ãƒ³ãƒ(,)ã‚’é™¤å»ã—ã¦ã‹ã‚‰isnumeric()ã‚’é©ç”¨ã™ã‚‹å‡¦ç†ã‚’è¿½åŠ 
        df_extracted['åˆ†é…é¡_cleaned'] = df_extracted['åˆ†é…é¡'].astype(str).str.replace(',', '', regex=False)
        df_cleaned = df_extracted[df_extracted['åˆ†é…é¡_cleaned'].str.isnumeric()].copy()
        df_cleaned['åˆ†é…é¡'] = df_cleaned['åˆ†é…é¡_cleaned'] # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ãŸåˆ†é…é¡ã§ä¸Šæ›¸ã
        
        # 4. ç‰¹æ®Šãªãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®ä½œæˆ
        
        # ç¾åœ¨æ™‚åˆ»ã‚’æ—¥æœ¬æ™‚é–“ã§å–å¾—
        now_jst = datetime.now(JST)
        update_time_str = now_jst.strftime('%Y/%m/%d %H:%M')
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ (1è¡Œç›®ã®ã¿3åˆ—ç›®ã«æ›´æ–°æ—¥æ™‚)
        # 1åˆ—ç›®: '', 2åˆ—ç›®: '', 3åˆ—ç›®: 'æ›´æ–°æ—¥æ™‚'
        header_row = pd.DataFrame([['', '', update_time_str]], columns=['åˆ†é…é¡', 'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID', 'æ›´æ–°æ—¥æ™‚'])
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å†æ§‹æˆ (3åˆ—ç›®ã‚’ç©ºã«è¨­å®š)
        df_data = pd.DataFrame({
            'åˆ†é…é¡': df_cleaned['åˆ†é…é¡'],
            'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID': df_cleaned['ã‚¢ã‚«ã‚¦ãƒ³ãƒˆID'],
            'æ›´æ–°æ—¥æ™‚': '' 
        })
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã¨ãƒ‡ãƒ¼ã‚¿è¡Œã‚’çµåˆ
        final_df = pd.concat([header_row, df_data], ignore_index=True)
        
        # CSVãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¸€æ™‚çš„ã«ãƒ¡ãƒ¢ãƒªã«æ›¸ãå‡ºã™
        csv_buffer = io.StringIO()
        # ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—ã€ã‚³ãƒ³ãƒåŒºåˆ‡ã‚Šã§æ›¸ãå‡ºã™
        # to_csvã®encodingã«ã¯ã€è¦ä»¶ã«ã‚ã‚‹ã€ŒCSV UTF-8ã€ã‚’æŒ‡å®š
        final_df.to_csv(csv_buffer, index=False, header=False, encoding='utf-8')
        
        st.success("ãƒ‡ãƒ¼ã‚¿ã®æ•´å½¢ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        st.code(csv_buffer.getvalue().split('\n')[:5], language='text') # æ•´å½¢å¾Œã®CSVãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        
        return csv_buffer
        
    except requests.HTTPError as e:
        st.error(f"HTTPã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e.response.status_code}. èªè¨¼CookieãŒç„¡åŠ¹ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        return None
    except ValueError:
        st.error("ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚å–å¾—ã—ãŸHTMLå†…ã«ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒæœŸå¾…ã™ã‚‹å½¢å¼ã¨ç•°ãªã‚Šã¾ã™ã€‚")
        st.error("`pandas.read_html`ãŒå£²ä¸Šãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚Cookieã‚„HTMLæ§‹é€ ã‚’å†ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None
    except Exception as e:
        st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        logging.error("ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»æ•´å½¢ã‚¨ãƒ©ãƒ¼", exc_info=True)
        return None

def upload_file_ftp(csv_buffer, ftp_config):
    """
    FTPã‚µãƒ¼ãƒãƒ¼ã«æ•´å½¢æ¸ˆã¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹
    """
    st.info(f"FTPã‚µãƒ¼ãƒãƒ¼ ({ftp_config['host']}) ã«æ¥ç¶šã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™...")
    
    try:
        csv_buffer.seek(0)
        # FTPæ¥ç¶š
        with FTP(ftp_config['host'], ftp_config['user'], ftp_config['password']) as ftp:
            # ã‚µãƒ¼ãƒãƒ¼ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            # ftplibã®storbinaryã¯ãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§è»¢é€ã™ã‚‹ãŸã‚ã€StringIOã‚’BytesIOã«å¤‰æ›ã™ã‚‹
            csv_bytes = csv_buffer.getvalue().encode('utf-8')
            
            # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            ftp.storbinary(f'STOR {ftp_config["target_path"]}', io.BytesIO(csv_bytes))
            
            st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            st.markdown(f"**ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆ:** `{ftp_config['host']}:{ftp_config['target_path']}`")
            
    except Exception as e:
        st.error(f"FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è¨­å®šï¼ˆãƒ›ã‚¹ãƒˆåã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã€ãƒ‘ã‚¹ï¼‰ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {e}")
        logging.error("FTPã‚¨ãƒ©ãƒ¼", exc_info=True)
        return False
        
    return True

# --- Streamlit UI ---

def main():
    st.set_page_config(page_title="SHOWROOMå£²ä¸Šãƒ‡ãƒ¼ã‚¿ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ„ãƒ¼ãƒ«", layout="wide")
    st.title("ãƒ©ã‚¤ãƒãƒ¼å£²ä¸Šãƒ‡ãƒ¼ã‚¿ è‡ªå‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ„ãƒ¼ãƒ« (ã‚¿ã‚¤ãƒ ãƒãƒ£ãƒ¼ã‚¸)")
    st.markdown("---")

    # 1. secretsã‹ã‚‰ã®è¨­å®šãƒ­ãƒ¼ãƒ‰
    try:
        sr_config = st.secrets["showroom"]
        ftp_config = st.secrets["ftp"]
    except KeyError:
        st.error("Secretsã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚`.streamlit/secrets.toml`ã‚’ç¢ºèªã—ã€[showroom]ã¨[ftp]ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    # 2. æœˆé¸æŠãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã®ä½œæˆ
    
    # é¸æŠè‚¢ã®ãƒªã‚¹ãƒˆã‚’å–å¾— (['YYYYå¹´MMæœˆåˆ†', timestamp])
    month_options = get_target_months()
    
    # ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ã«è¡¨ç¤ºã™ã‚‹æ–‡å­—åˆ—ã®ã¿ã‚’æŠ½å‡º
    month_labels = [label for label, _ in month_options]
    
    st.header("1. å¯¾è±¡æœˆé¸æŠ")
    
    selected_label = st.selectbox(
        "å‡¦ç†å¯¾è±¡ã®é…ä¿¡æœˆã‚’é¸æŠã—ã¦ãã ã•ã„:",
        options=month_labels,
        index=0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€æ–°ã®æœˆã‚’é¸æŠ
    )
    
    # é¸æŠã•ã‚ŒãŸãƒ©ãƒ™ãƒ«ã‹ã‚‰å¯¾å¿œã™ã‚‹ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ¤œç´¢
    selected_timestamp = next((ts for label, ts in month_options if label == selected_label), None)

    if selected_timestamp is None:
        st.warning("æœ‰åŠ¹ãªæœˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
        
    # ç¢ºèªã®ãŸã‚ã®å‡ºåŠ›ã€‚ã“ã“ã§æ­£ã—ã„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¯ãšã§ã™ã€‚
    st.info(f"é¸æŠã•ã‚ŒãŸæœˆ: **{selected_label}** (UNIXã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {selected_timestamp})")
    
    st.header("2. ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å®Ÿè¡Œ")
    
    # 3. å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("ğŸš€ ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»æ•´å½¢ãƒ»FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ", type="primary"):
        with st.spinner(f"å‡¦ç†ä¸­: {selected_label}ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ã„ã¾ã™..."):
            
            # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—ã¨æ•´å½¢
            csv_buffer = fetch_and_process_data(selected_timestamp, sr_config['auth_cookie_string'])
            
            if csv_buffer:
                # 2. FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                upload_file_ftp(csv_buffer, ftp_config)
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»æ•´å½¢ã«å¤±æ•—ã—ãŸãŸã‚ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
